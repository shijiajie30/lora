# CSV æ•°æ®é›†è®­ç»ƒæŒ‡å—

## ğŸ“‹ CSV æ•°æ®é›†è¯´æ˜

### æ•°æ®é›†ä¿¡æ¯
- **æ–‡ä»¶**: `datasets/19503488-349b-4321-941d-7875fca0737b.csv`
- **æ ·æœ¬æ•°**: 1,000 æ¡
- **æ ¼å¼**: CSV (é€—å·åˆ†éš”)

### æ•°æ®æ ¼å¼

CSV æ–‡ä»¶åŒ…å« 3 åˆ—ï¼š

| åˆ—å | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `input` | é¢å¤–çš„è¾“å…¥å†…å®¹ | é€šå¸¸ä¸ºç©ºå­—ç¬¦ä¸² "" |
| `instruction` | é—®é¢˜/æŒ‡ä»¤ | "åˆ†ææŒªç”¨ç‰¹å®šæ¬¾ç‰©ç½ªçš„æ³•å¾‹åæœ..." |
| `output` | æœŸæœ›çš„å›ç­” | "æŒªç”¨ç‰¹å®šæ¬¾ç‰©ç½ªæ˜¯æŒ‡..." |

### æ•°æ®ç¤ºä¾‹

```csv
input,instruction,output
"",åˆ†ææŒªç”¨ç‰¹å®šæ¬¾ç‰©ç½ªçš„æ³•å¾‹åæœ...,æŒªç”¨ç‰¹å®šæ¬¾ç‰©ç½ªæ˜¯æŒ‡...
"",åˆ†æåœ¨è¿é€ä»–äººå·è¶Šå›½ï¼ˆè¾¹ï¼‰å¢ƒ...,æ ¹æ®æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœåœ¨è¿é€...
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: ä½¿ç”¨ä¾¿æ·è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
./train_csv.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ… æ£€æŸ¥ CSV æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- âœ… æ˜¾ç¤ºæ ·æœ¬æ•°é‡
- âœ… ä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°å¼€å§‹è®­ç»ƒ

### æ–¹å¼ 2: ç›´æ¥è¿è¡Œ Pythonï¼ˆè‡ªå®šä¹‰å‚æ•°ï¼‰

```bash
python train.py \
  --dataset_name ./datasets/19503488-349b-4321-941d-7875fca0737b.csv \
  --dataset_type csv
```

### æ–¹å¼ 3: è‡ªåŠ¨æ£€æµ‹ï¼ˆæœ€ç®€å•ï¼‰

```bash
# åªè¦æ–‡ä»¶åä»¥ .csv ç»“å°¾ï¼Œä¼šè‡ªåŠ¨æ£€æµ‹ä¸º CSV æ ¼å¼
python train.py \
  --dataset_name ./datasets/19503488-349b-4321-941d-7875fca0737b.csv
```

## âš™ï¸ è®­ç»ƒå‚æ•°

### é»˜è®¤å‚æ•°ï¼ˆé€‚åˆ 3B æ¨¡å‹ï¼‰

```bash
python train.py \
  --dataset_name ./datasets/19503488-349b-4321-941d-7875fca0737b.csv \
  --model_name ./models/LLM-Research/Llama-3.2-3B-Instruct \
  --num_epochs 3 \
  --batch_size 2 \
  --gradient_accumulation_steps 8 \
  --learning_rate 1e-4 \
  --max_length 512 \
  --lora_r 32 \
  --lora_alpha 64 \
  --lora_dropout 0.1
```

### macOS ä¼˜åŒ–å‚æ•°ï¼ˆå†…å­˜å—é™ï¼‰

```bash
python train.py \
  --dataset_name ./datasets/19503488-349b-4321-941d-7875fca0737b.csv \
  --batch_size 1 \
  --gradient_accumulation_steps 16 \
  --max_length 384 \
  --lora_r 16 \
  --lora_alpha 32 \
  --num_epochs 2
```

## ğŸ“Š æ•°æ®é›†å¯¹æ¯”

| ç‰¹æ€§ | CSV æ•°æ®é›† | åŸ HuggingFace æ•°æ®é›† |
|------|-----------|---------------------|
| æ ·æœ¬æ•° | 1,000 | 21,476 |
| æ ¼å¼ | CSV æ–‡ä»¶ | Arrow ç¼“å­˜ |
| åŠ è½½é€Ÿåº¦ | å¿« | å¾ˆå¿« |
| è®­ç»ƒæ—¶é—´ | çº¦ 30-45 åˆ†é’Ÿ (M2 Max) | çº¦ 12-18 å°æ—¶ (M2 Max) |
| ç£ç›˜å ç”¨ | ~1 MB | ~46 MB |

**ä¼˜åŠ¿**:
- âœ… **æ ·æœ¬æ•°è¾ƒå°‘**ï¼Œè®­ç»ƒæ›´å¿«ï¼ˆçº¦ä¸ºåŸæ•°æ®é›†çš„ 1/20ï¼‰
- âœ… **é€‚åˆå¿«é€Ÿå®éªŒ**å’Œè°ƒè¯•
- âœ… **æ–‡ä»¶å°**ï¼Œæ˜“äºç¼–è¾‘å’ŒæŸ¥çœ‹
- âœ… **æ ¼å¼ç®€å•**ï¼Œä¾¿äºè‡ªå®šä¹‰æ•°æ®

## â±ï¸ è®­ç»ƒæ—¶é—´é¢„ä¼°

### CSV æ•°æ®é›† (1,000 æ ·æœ¬ï¼Œ3 epochs)

| è®¾å¤‡ | é…ç½® | é¢„è®¡æ—¶é—´ |
|------|------|---------|
| **CUDA GPU** | | |
| RTX 3090 (24GB) | batch=2, acc=8, 4-bit | 20-30 åˆ†é’Ÿ |
| RTX 4090 (24GB) | batch=4, acc=4, 4-bit | 15-20 åˆ†é’Ÿ |
| A100 (40GB) | batch=4, acc=4, 4-bit | 10-15 åˆ†é’Ÿ |
| **Apple Silicon** | | |
| M1 Pro (16GB) | batch=1, len=384 | 1-2 å°æ—¶ |
| M2 Max (32GB) | batch=2, len=512 | 30-45 åˆ†é’Ÿ |
| M3 Max (64GB) | batch=4, len=512 | 20-30 åˆ†é’Ÿ |

*ç›¸æ¯”åŸæ•°æ®é›†ï¼ˆ21,476 æ ·æœ¬ï¼‰ï¼Œè®­ç»ƒæ—¶é—´çº¦ä¸º 1/20*

## ğŸ“ CSV æ•°æ®é›†çš„ä¼˜åŠ¿

### 1. å¿«é€Ÿè¿­ä»£
- æ ·æœ¬æ•°å°‘ï¼Œè®­ç»ƒå¿«
- é€‚åˆæµ‹è¯•ä¸åŒçš„è¶…å‚æ•°
- å¿«é€ŸéªŒè¯æƒ³æ³•

### 2. æ˜“äºå®šåˆ¶
```bash
# ç¼–è¾‘ CSV æ–‡ä»¶
vi ./datasets/19503488-349b-4321-941d-7875fca0737b.csv

# æˆ–ä½¿ç”¨ Python
import pandas as pd
df = pd.read_csv('./datasets/19503488-349b-4321-941d-7875fca0737b.csv')
# ç­›é€‰ã€ä¿®æ”¹æ•°æ®
df.to_csv('./datasets/my_custom_data.csv', index=False)
```

### 3. ç»„åˆæ•°æ®é›†
```python
import pandas as pd

# åŠ è½½å¤šä¸ªCSV
df1 = pd.read_csv('./datasets/data1.csv')
df2 = pd.read_csv('./datasets/data2.csv')

# åˆå¹¶
combined = pd.concat([df1, df2], ignore_index=True)

# å»é‡
combined = combined.drop_duplicates()

# ä¿å­˜
combined.to_csv('./datasets/combined.csv', index=False)
```

## ğŸ”§ ä½¿ç”¨è‡ªå·±çš„ CSV æ•°æ®

### CSV æ ¼å¼è¦æ±‚

å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š
- `instruction`: é—®é¢˜æˆ–æŒ‡ä»¤ï¼ˆå¿…éœ€ï¼‰
- `output`: æœŸæœ›çš„å›ç­”ï¼ˆå¿…éœ€ï¼‰
- `input`: é¢å¤–çš„è¾“å…¥å†…å®¹ï¼ˆå¯é€‰ï¼Œå¯ä»¥ä¸ºç©ºï¼‰

### åˆ›å»ºè‡ªå®šä¹‰ CSV

```python
import pandas as pd

# å‡†å¤‡æ•°æ®
data = {
    'input': ['', '', ''],  # å¯ä»¥ä¸ºç©º
    'instruction': [
        'ä»€ä¹ˆæ˜¯åˆåŒæ³•ï¼Ÿ',
        'å¦‚ä½•èµ·è¯‰ï¼Ÿ',
        'åŠ³åŠ¨åˆåŒçº çº·æ€ä¹ˆå¤„ç†ï¼Ÿ'
    ],
    'output': [
        'åˆåŒæ³•æ˜¯è§„èŒƒåˆåŒå…³ç³»çš„æ³•å¾‹...',
        'èµ·è¯‰æµç¨‹åŒ…æ‹¬ï¼š1. å‡†å¤‡ææ–™...',
        'åŠ³åŠ¨åˆåŒçº çº·å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼...'
    ]
}

# åˆ›å»º DataFrame
df = pd.DataFrame(data)

# ä¿å­˜ä¸º CSV
df.to_csv('./datasets/my_data.csv', index=False, encoding='utf-8')
```

### ä½¿ç”¨è‡ªå®šä¹‰ CSV è®­ç»ƒ

```bash
python train.py \
  --dataset_name ./datasets/my_data.csv \
  --dataset_type csv
```

## ğŸ¯ æ•°æ®è´¨é‡å»ºè®®

### 1. æ•°æ®æ¸…æ´—
- ç§»é™¤é‡å¤æ ·æœ¬
- æ£€æŸ¥æ ¼å¼æ˜¯å¦æ­£ç¡®
- ç¡®ä¿ instruction å’Œ output éƒ½æœ‰å†…å®¹

### 2. æ•°æ®å¹³è¡¡
- ä¸åŒä¸»é¢˜çš„æ ·æœ¬è¦å‡è¡¡
- é¿å…æŸä¸€ç±»é—®é¢˜è¿‡å¤š

### 3. è´¨é‡æ£€æŸ¥
```python
import pandas as pd

df = pd.read_csv('./datasets/19503488-349b-4321-941d-7875fca0737b.csv')

# æ£€æŸ¥ç¼ºå¤±å€¼
print(df.isnull().sum())

# æ£€æŸ¥ç©ºå­—ç¬¦ä¸²
print((df['instruction'] == '').sum())
print((df['output'] == '').sum())

# æŸ¥çœ‹é•¿åº¦åˆ†å¸ƒ
print(df['instruction'].str.len().describe())
print(df['output'].str.len().describe())
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CSV æ–‡ä»¶è¯»å–é”™è¯¯

**é”™è¯¯**: `UnicodeDecodeError` æˆ–ä¹±ç 

**è§£å†³**:
```python
# æ£€æŸ¥å¹¶è½¬æ¢ç¼–ç 
import pandas as pd

df = pd.read_csv('./datasets/data.csv', encoding='utf-8')
# æˆ–
df = pd.read_csv('./datasets/data.csv', encoding='gbk')

# ä¿å­˜ä¸º UTF-8
df.to_csv('./datasets/data_utf8.csv', index=False, encoding='utf-8')
```

### Q2: è®­ç»ƒæ—¶å‡ºç° NaN æˆ–ç©ºå€¼

**åŸå› **: CSV ä¸­æœ‰ç¼ºå¤±æ•°æ®

**è§£å†³**:
```python
import pandas as pd

df = pd.read_csv('./datasets/data.csv')

# åˆ é™¤æœ‰ç¼ºå¤±å€¼çš„è¡Œ
df = df.dropna()

# æˆ–å¡«å……ç¼ºå¤±å€¼
df['input'] = df['input'].fillna('')

df.to_csv('./datasets/data_cleaned.csv', index=False)
```

### Q3: æ•°æ®é›†å¤ªå°æ•ˆæœä¸å¥½

**å»ºè®®**:
1. å¢åŠ è®­ç»ƒè½®æ•°ï¼š`--num_epochs 5`
2. ä½¿ç”¨æ›´å¤§çš„ LoRA ç§©ï¼š`--lora_r 64`
3. æ•°æ®å¢å¼ºï¼šåŒä¹‰æ”¹å†™ã€é—®é¢˜å˜æ¢
4. ç»“åˆå¤šä¸ªæ•°æ®æº

### Q4: å¦‚ä½•éªŒè¯æ¨¡å‹æ•ˆæœï¼Ÿ

```bash
# è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨æµ‹è¯•é—®é¢˜éªŒè¯
python inference.py \
  --lora_weights ./output/llama-lora-xxx/final_model \
  --prompt "åˆ†æåˆåŒè¿çº¦çš„æ³•å¾‹è´£ä»»" \
  --interactive
```

## ğŸ“š å‚è€ƒç¤ºä¾‹

### æ•°æ®é¢„å¤„ç†è„šæœ¬

```python
# preprocess_csv.py
import pandas as pd

def clean_data(csv_path):
    """æ¸…æ´—å’Œé¢„å¤„ç† CSV æ•°æ®"""
    df = pd.read_csv(csv_path)
    
    print(f"åŸå§‹æ ·æœ¬æ•°: {len(df)}")
    
    # åˆ é™¤ç¼ºå¤±å€¼
    df = df.dropna()
    print(f"åˆ é™¤ç¼ºå¤±å€¼å: {len(df)}")
    
    # åˆ é™¤é‡å¤
    df = df.drop_duplicates(subset=['instruction', 'output'])
    print(f"åˆ é™¤é‡å¤å: {len(df)}")
    
    # è¿‡æ»¤å¤ªçŸ­çš„æ ·æœ¬
    df = df[df['instruction'].str.len() > 10]
    df = df[df['output'].str.len() > 20]
    print(f"è¿‡æ»¤çŸ­æ–‡æœ¬å: {len(df)}")
    
    # å¡«å……ç©ºçš„ input
    df['input'] = df['input'].fillna('')
    
    # æ‰“ä¹±é¡ºåº
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    return df

# ä½¿ç”¨
df = clean_data('./datasets/raw_data.csv')
df.to_csv('./datasets/cleaned_data.csv', index=False, encoding='utf-8')
print("âœ“ æ•°æ®æ¸…æ´—å®Œæˆï¼")
```

### æ•°æ®é›†æ‹†åˆ†ï¼ˆè®­ç»ƒ/éªŒè¯ï¼‰

```python
import pandas as pd
from sklearn.model_selection import train_test_split

df = pd.read_csv('./datasets/19503488-349b-4321-941d-7875fca0737b.csv')

# æ‹†åˆ† 90% è®­ç»ƒï¼Œ10% éªŒè¯
train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)

train_df.to_csv('./datasets/train.csv', index=False)
val_df.to_csv('./datasets/val.csv', index=False)

print(f"è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_df)} æ ·æœ¬")
```

---

ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ CSV æ•°æ®é›†å¼€å§‹è®­ç»ƒäº†ï¼å»ºè®®å…ˆç”¨å°å‚æ•°å¿«é€Ÿæµ‹è¯•ï¼Œç¡®ä¿ä¸€åˆ‡æ­£å¸¸åå†è¿›è¡Œå®Œæ•´è®­ç»ƒã€‚ğŸš€

**å¿«é€Ÿå¼€å§‹**:
```bash
./train_csv.sh
```

æˆ–æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼š`README.md` å’Œ `README_MACOS.md`

